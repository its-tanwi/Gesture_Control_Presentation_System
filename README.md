# ğŸ¯ Gesture-Controlled Presentation Navigation

**Gesture-Controlled Presentation Navigation** is a lightweight Python project that enables hands-free control of presentations using hand gestures tracked via **MediaPipe** and interpreted using **PyAutoGUI**.

This tool is ideal for presenters, educators, and accessibility advocates who want to navigate slides and zoom without touching a keyboard or mouse.

---

## âœ¨ Features

- âœ‹ **Zoom In**: Spread all fingers open ğŸ–ï¸
- ğŸ¤ **Zoom Out**: Show "L" shape (Thumb + Index)  
- â˜ï¸ **Page Up**: Raise index finger only  
- âœŒï¸ **Page Down**: Raise index + middle fingers (peace sign)  
- ğŸ“± **Camera Input**: Uses your webcam (DroidCam optional for phone input)
- âš¡ **Real-time Detection**: Powered by MediaPipe with low latency
- ğŸªŸ **Lightweight**: No GUI, minimal dependencies, terminal-based

---

## ğŸ§  How It Works

The system detects specific hand landmarks using **MediaPipe**, interprets gestures based on finger positions, and sends keyboard events via **PyAutoGUI**.

- Gesture â†’ Interpreted Action â†’ OS Keystroke  
  e.g. âœŒï¸ â†’ `'page_down'` â†’ `pyautogui.press(' ')`

---




## ğŸš€ Installation

### 1. Clone this repository:
```bash
git clone https://github.com/its-tanwi/gesturecontrolledPresentations.git
cd gesturecontrolledPresentations

---

### 2. Install dependencies:
```bash
pip install -r requirements.txt

---

### 3. Run the application:
```bash
python GesturePresentationControl.py

---

## ğŸ§° Target Audience
ğŸ™ï¸ Presenters and Educators looking for seamless slide navigation

ğŸ¤– Tech Enthusiasts and Developers interested in gesture recognition

ğŸ§  Accessibility Advocates building inclusive interfaces

ğŸ® Gamers and Researchers exploring HCI or hands-free control systems






